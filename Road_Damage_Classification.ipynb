{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Automated Road Damage Classification System\n",
                "## deep learning project with Computer Vision & Grad-CAM Visualization\n",
                "\n",
                "**Project Goal:** Detect and classify road damage (Potholes, Cracks, Manholes) and provide actionable maintenance recommendations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, optimizers\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "from sklearn.utils import class_weight\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import cv2\n",
                "import random\n",
                "\n",
                "# Set Paths\n",
                "BASE_DIR = r\"D:\\Intern Project\\Final Project\\data\"\n",
                "IMAGE_DIR = os.path.join(BASE_DIR, \"images\")\n",
                "LABEL_DIR = os.path.join(BASE_DIR, \"labels\")\n",
                "\n",
                "# CONFIGURATION\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32\n",
                "CLASSES = ['Pothole', 'Crack', 'Manhole']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1: Data Preparation\n",
                "Loading images and labels, handling resizing, normalization, and augmentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dataset():\n",
                "    image_paths = []\n",
                "    labels = []\n",
                "    \n",
                "    for label_file in os.listdir(LABEL_DIR):\n",
                "        if label_file.endswith('.txt'):\n",
                "            img_name = label_file.replace('.txt', '.jpg')\n",
                "            img_path = os.path.join(IMAGE_DIR, img_name)\n",
                "            \n",
                "            if os.path.exists(img_path):\n",
                "                with open(os.path.join(LABEL_DIR, label_file), 'r') as f:\n",
                "                    line = f.readline()\n",
                "                    if line:\n",
                "                        class_id = int(line.split()[0])\n",
                "                        if class_id < 3:\n",
                "                            image_paths.append(img_path)\n",
                "                            labels.append(class_id)\n",
                "    return np.array(image_paths), np.array(labels)\n",
                "\n",
                "paths, y_data = load_dataset()\n",
                "print(f\"Dataset: {len(paths)} images across {len(CLASSES)} classes.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### handling Class Imbalance and Data Augmentation\n",
                "Applying class weights to ensure the model doesn't drift toward the majority class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate Class Weights\n",
                "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_data), y=y_data)\n",
                "class_weights = dict(enumerate(weights))\n",
                "print(f\"Calculated Class Weights: {class_weights}\")\n",
                "\n",
                "# Data Augmentation Setup (Including Brightness and Blur as requested)\n",
                "datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=20,\n",
                "    width_shift_range=0.2,\n",
                "    height_shift_range=0.2,\n",
                "    brightness_range=[0.8, 1.2], # Brightness adjustment\n",
                "    horizontal_flip=True,\n",
                "    validation_split=0.2\n",
                ")\n",
                "\n",
                "df = pd.DataFrame({'filename': paths, 'class': y_data.astype(str)})\n",
                "\n",
                "train_gen = datagen.flow_from_dataframe(\n",
                "    df, x_col='filename', y_col='class',\n",
                "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical', subset='training'\n",
                ")\n",
                "\n",
                "val_gen = datagen.flow_from_dataframe(\n",
                "    df, x_col='filename', y_col='class',\n",
                "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical', subset='validation', shuffle=False\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Model Development\n",
                "Building a Baseline CNN and then performing Transfer Learning with MobileNetV2."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Baseline Model\n",
                "def build_baseline():\n",
                "    model = models.Sequential([\n",
                "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
                "        layers.MaxPooling2D(2,2),\n",
                "        layers.Conv2D(64, (3,3), activation='relu'),\n",
                "        layers.MaxPooling2D(2,2),\n",
                "        layers.Flatten(),\n",
                "        layers.Dense(64, activation='relu'),\n",
                "        layers.Dense(3, activation='softmax')\n",
                "    ])\n",
                "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "    return model\n",
                "\n",
                "# 2. Transfer Learning (Recommended: MobileNetV2 for Lightweight deployment)\n",
                "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
                "base_model.trainable = True\n",
                "\n",
                "# Fine-tune from this layer onwards (Fine-tuning selected layers)\n",
                "fine_tune_at = 100\n",
                "for layer in base_model.layers[:fine_tune_at]:\n",
                "    layer.trainable = False\n",
                "\n",
                "model = models.Sequential([\n",
                "    base_model,\n",
                "    layers.GlobalAveragePooling2D(),\n",
                "    layers.Dense(256, activation='relu'),\n",
                "    layers.Dropout(0.4),\n",
                "    layers.Dense(3, activation='softmax')\n",
                "])\n",
                "\n",
                "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), \n",
                "              loss='categorical_crossentropy', \n",
                "              metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Model Evaluation\n",
                "Training the model and checking Precision, Recall, and Confusion Matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "history = model.fit(\n",
                "    train_gen,\n",
                "    validation_data=val_gen,\n",
                "    epochs=10,\n",
                "    class_weight=class_weights\n",
                ")\n",
                "\n",
                "# Detailed Evaluation\n",
                "y_true = val_gen.classes\n",
                "y_pred = np.argmax(model.predict(val_gen), axis=1)\n",
                "\n",
                "print(\"Classification Report:\")\n",
                "print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
                "\n",
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(8,6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explainable AI: Grad-CAM Implementation\n",
                "Visualizing which pixels influenced the model's decision."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_gradcam(img_array, model, last_conv_layer_name):\n",
                "    grad_model = tf.keras.models.Model(\n",
                "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
                "    )\n",
                "\n",
                "    with tf.GradientTape() as tape:\n",
                "        last_conv_layer_output, preds = grad_model(img_array)\n",
                "        top_pred_index = tf.argmax(preds[0])\n",
                "        top_class_channel = preds[:, top_pred_index]\n",
                "\n",
                "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
                "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
                "\n",
                "    last_conv_layer_output = last_conv_layer_output[0]\n",
                "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
                "    heatmap = tf.squeeze(heatmap)\n",
                "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
                "    return heatmap.numpy()\n",
                "\n",
                "# Save model for deployment\n",
                "model.save(\"road_damage_final_model.h5\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}